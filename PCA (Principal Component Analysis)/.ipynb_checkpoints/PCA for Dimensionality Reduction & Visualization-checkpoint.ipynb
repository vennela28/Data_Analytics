{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a dataset X is 2-D and there are n-points \n",
    "\n",
    "      f₁   f₂    \n",
    "\n",
    "    x₁\n",
    "\n",
    "    x₂\n",
    "    .\n",
    "    .    \n",
    "X =\n",
    "\n",
    "    xᵢ                         \n",
    "    . \n",
    "    .\n",
    "    xₙ\n",
    "    \n",
    "Convert the above dataset from 2-D to 1-D. - maximum variance method (PCA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computed Eigen values and Eigen vectors of S as Sₔₓₔ = Xᵀₔₓₙ Xₙₓₔ. \n",
    "\n",
    "v₁ is a top Eigen vector corresponding to  λ₁.\n",
    "\n",
    "v₂ is a second top Eigen vector corresponding to λ₂.\n",
    "\n",
    "Convert a 2-D dataset to 1-D dataset - Instead of projecting the data on f₁(x-axis) axis, the best direction of projection is v₁ (explains the variance, ∴ retaining most of the information. \n",
    "\n",
    "<h6>Dimensionality Reduction - Maximum variance method (PCA)</h6>\n",
    "\n",
    "        v₁    \n",
    "\n",
    "    1\n",
    "    2\n",
    "    .\n",
    "    .    \n",
    "X =\n",
    "\n",
    "    i   xᵢ'                  \n",
    "    . \n",
    "    .\n",
    "    n\n",
    "\n",
    "\n",
    "Create a new dataset X' which is 1-D and the dimension is v₁ having n-points. iᵗʰ point is xᵢ'.\n",
    "xᵢ' = xᵢᵀv₁. Projecting point xᵢ on v₁ axis. Feature has been changed to v₁ from f₁(x-axis) f₂(y-axis). Since v₁ is 1-D in which the variance is maximal, so converting the data from 2-D to 1-D \n",
    "- projecting the data onto v₁\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider 10-D dataset as\n",
    "\n",
    "       f₁   f₂   .   .   .  .  f₁₀    \n",
    "\n",
    "    1\n",
    "    2\n",
    "    .\n",
    "    .    \n",
    "X =\n",
    "    i        xᵢᵀ\n",
    "    . \n",
    "    .\n",
    "    n                               ₙₓ₁₀ \n",
    "    \n",
    "Now visualize these points. \n",
    "\n",
    "Convert the above matrix X into X'.\n",
    "\n",
    "        v₁    v₂\n",
    "\n",
    "    1\n",
    "    2\n",
    "    .\n",
    "    .    \n",
    "X' =\n",
    "\n",
    "    i       xᵢ'ᵀ           \n",
    "    . \n",
    "    .\n",
    "    n               ₙₓ₂\n",
    "    \n",
    "We take the matrix X and compute S = XᵀX. Now compute the Eigen values and Eigen vectors of S. Eigen values of S - eigen(S) = λ₁ >= λ₂ >= ... λ₁₀. For each eigen value, we get Eigen vector v₁, v₂, ... v₁₀. I know v₁ and v₂ are the best dimensions which will preserve most of the information. After dimensionality reduction, using PCA create a new data matrix.\n",
    "Create a new data matrix called X' such that for each point Xᵢ there is a point xᵢ' = [xᵢᵀv₁, xᵢᵀv₂].\n",
    "\n",
    "If we have 100-D data. In machine learning, we use PCA for converting this data into 50 dimensions. In this case we take the top 50 Eigen vectors. When we compute S₁₀₀ₓ₁₀₀ = XᵀX. We will have Eigen values of S, eigen(S) = λ₁ >= λ₂ >= ... λ₁₀₀. For each Eigen value we get Eigen vectors, v₁, v₂, ... v₁₀₀. We take the top 50 Eigen vectors and do projections. Given any point xᵢ', jᵗʰ component we get xᵢⱼ' = xᵢᵀvⱼ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset of 100 dimensions D, we can have a dataset of D' dimensions such that D > D'\n",
    "\n",
    "We have a data set xᵢ ∈ R¹⁰⁰. We have to compute xᵢ' ∈ Rᴰ', such that D' < 100 but want to preserve 99% of the variance. \n",
    "\n",
    "Let λ₁ + λ₂ + ... + λ₅₁ / Σ\tλᵢ (i = 1 to 100) = 0.99, this means we use the top 51 Eigen vectors, I can explain 99% of the variance in my data. In this case we make D' = 51. So we cn reduce the dimensionality from D to D' using PCA, preserving 99% or 90% of the information. \n",
    "\n",
    "For visualization, we visualize 2-D data; so we can take the top 2 Eigen vectors, v₁ and v₂ for visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
